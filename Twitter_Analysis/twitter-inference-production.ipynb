{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving Our Twitter Inference Towards Production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.softwareadvice.com/resources/wp-content/uploads/The-Best-Free-Tools-for-Twitter-Sentiment-Analysis-Tile.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Question:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the probability that a tweet originating from within Colombia contains at least 1 occurence of the word \"yo\" with any given composition of accents, and capital and lowercase letters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather data (Extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tweepy\n",
    "from tweepy import Stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardar en variables para no dejar las key expuestas\n",
    "\n",
    "CONSUMER_KEY = \"7IcU2nins8i2xporqmdB9jSvd\"\n",
    "CONSUMER_SECRET = \"wIsiRpZaOHsMPRckbjmZwo44fsLql1VyKsUiDQzd6rN978rmxt\"\n",
    "\n",
    "ACCESS_TOKEN = \"200195839-3xrk66Par46KPQRU9jbbINXDC7Hd2x9HJS2oDSWG\"\n",
    "ACCESS_TOKEN_SECRET = \"2Q7NswDvZMjDRwI1b6NdlynMlcVfaWyV4emUe5g3PqlXf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOMBIA_GEO_LOCATION_BOUNDING_BOX = [-78.31, 0.44, -70.71, 11.39]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create connection with twitter API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define some cleaning functions (Transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "\n",
    "\n",
    "def make_lowercase(tweet):\n",
    "    return tweet.lower()\n",
    "\n",
    "\n",
    "def remove_diacritics(tweet):\n",
    "    return unidecode(tweet)\n",
    "\n",
    "\n",
    "def remove_non_alpha_characters(tweet):\n",
    "    return ''.join(character for character in tweet if character.isalpha() or character == ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Driver=SQL Server;Server=bielondono;Database=twitter_inference;Trusted_Connection=Yes;'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyodbc # Library to manage odbc connection in this case we work with SQl SERVER\n",
    "\n",
    "CNXN_STRING = \"Driver=SQL Server;Server={SERVER};Database={DB_NAME};Trusted_Connection=Yes;\"\n",
    "# you can also swap Trusted_Connection for UID={your username};PWD={your password}\n",
    "\n",
    "#Parameters of database\n",
    "DB_NAME = \"twitter_inference\"\n",
    "TBL_NAME =\"tweets\"\n",
    "SERVER = \"bielondono\"\n",
    "\n",
    "CNXN_STRING.format(SERVER=SERVER, DB_NAME=DB_NAME)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Create DB and Table  from python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database created\n",
      "New Table Created: tweets\n"
     ]
    }
   ],
   "source": [
    "#Create DB\n",
    "\n",
    "cnxn_master = pyodbc.connect(CNXN_STRING.format(SERVER=SERVER, DB_NAME=\"master\"), autocommit=True)\n",
    "cnxn_master.cursor().execute(\"IF EXISTS(SELECT * FROM sys.databases WHERE [name] = '{0}') DROP DATABASE {0}\".format(DB_NAME))\n",
    "cnxn_master.cursor().execute(\"CREATE DATABASE \" + DB_NAME)\n",
    "cnxn_master.close()\n",
    "\n",
    "print(\"Database created\")\n",
    "\n",
    "# Creating Table\n",
    "\n",
    "Script_Create_TBL = \"CREATE TABLE {0} (id_str varchar(50), text varchar(500))\".format(TBL_NAME)\n",
    "\n",
    "cnxn_db = pyodbc.connect(CNXN_STRING.format(SERVER=SERVER, DB_NAME=DB_NAME), autocommit=True)\n",
    "cnxn_db.cursor().execute(\"IF EXISTS(select* from INFORMATION_SCHEMA.TABLES WHERE [TABLE_NAME] = '{0}') DROP TABLE {0}\".format(TBL_NAME))\n",
    "cnxn_db.cursor().execute(Script_Create_TBL)\n",
    "cnxn_db.close()\n",
    "\n",
    "print(\"New Table Created: {0}\".format(TBL_NAME))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the Stream Listener twitter api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweepy import StreamListener\n",
    "\n",
    "\n",
    "class PersistedStreamListener(StreamListener):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._database_connection = pyodbc.connect(CNXN_STRING.format(SERVER=SERVER, DB_NAME=DB_NAME), autocommit=True)\n",
    "        super().__init__()\n",
    "    \n",
    "    def on_status(self, status):\n",
    "        cleaned_status_text = self._clean_status_text(status.text)\n",
    "        self._insert_status(id_str=status.id_str, text=cleaned_status_text)\n",
    "        \n",
    "    def _clean_status_text(self, status_text):\n",
    "        cleaned_status_text = status_text\n",
    "        for cleaning_function in self._cleaning_functions:\n",
    "            cleaned_status_text = cleaning_function(cleaned_status_text)\n",
    "        return cleaned_status_text\n",
    "    \n",
    "    def _insert_status(self, id_str, text):\n",
    "        cursor = self._database_connection.cursor()\n",
    "        insert_statement = \"\"\"INSERT INTO {table_name} VALUES ('{id_str}', '{text}')\"\"\".format(\n",
    "                table_name=TBL_NAME, id_str=id_str, text=text)\n",
    "\n",
    "        cursor.execute(insert_statement)\n",
    "        self._database_connection.commit()\n",
    "        \n",
    "        cursor.close()\n",
    "        \n",
    "    @property\n",
    "    def _cleaning_functions(self):\n",
    "        return [make_lowercase, remove_diacritics, remove_non_alpha_characters]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activate de persisted stream listener (Load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_api = Stream(auth=auth, listener=PersistedStreamListener())\n",
    "\n",
    "#filter the stream api by location\n",
    "\n",
    "streaming_api.filter(locations=COLOMBIA_GEO_LOCATION_BOUNDING_BOX, async=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling data in stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import beta as beta_distribution\n",
    "\n",
    "X_VALUES = np.linspace(0, 1, 1002)[1:-1]\n",
    "DATABASE_CONNECTION = pyodbc.connect(CNXN_STRING.format(SERVER=SERVER,DB_NAME=DB_NAME), autocommit=True)\n",
    "KEYWORD =\"yo\"\n",
    "\n",
    "def fetch_tweets(database_connection=DATABASE_CONNECTION):\n",
    "    cursor = database_connection.cursor()\n",
    "    select_statement = \"\"\"SELECT text FROM {table}\"\"\".format(table=TBL_NAME)\n",
    "    cursor.execute(select_statement)\n",
    "    result = cursor.fetchall()\n",
    "    \n",
    "    return [tweet[0] for tweet in result]\n",
    "\n",
    "\n",
    "def compute_alpha_and_beta(tweets, keyword=KEYWORD):\n",
    "    number_of_occurences = sum(keyword in tweet for tweet in tweets)\n",
    "    alpha = 1 + number_of_occurences\n",
    "    beta = 1 + (len(tweets) - number_of_occurences)\n",
    "    \n",
    "    return alpha, beta\n",
    "\n",
    "\n",
    "def compute_pdf_y_values(alpha, beta, x_values=X_VALUES):\n",
    "    return beta_distribution(alpha, beta).pdf(x_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monotiring data live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esteban.londono\\AppData\\Local\\Continuum\\anaconda3\\envs\\DS_Beginner\\lib\\site-packages\\bokeh\\client\\session.py:353: UserWarning: \n",
      "\n",
      "    !!!! PLEASE NOTE !!!!\n",
      "\n",
      "The use of `session.loop_until_closed` and `push_session` to run Bokeh\n",
      "application code outside a Bokeh server is **HIGHLY DISCOURAGED** for any real\n",
      "use.\n",
      "\n",
      "Running application code outside a Bokeh server with bokeh.client in this way\n",
      "has (and always will have) several intrinsic drawbacks:\n",
      "\n",
      "* Fast binary array transport is NOT available! Base64 fallback is much slower\n",
      "* All network traffic is DOUBLED due to extra hop between client and server\n",
      "* Server *and* client process must be running at ALL TIMES for callbacks to work\n",
      "* App code run outside the Bokeh server is NOT SCALABLE behind a load balancer\n",
      "\n",
      "The bokeh.client API is recommended to use ONLY for testing, or for customizing\n",
      "individual sessions running in a full Bokeh server, before passing on to viewers.\n",
      "\n",
      "For information about different ways of running apps in a Bokeh server, see:\n",
      "\n",
      "    http://bokeh.pydata.org/en/latest/docs/user_guide/server.html\n",
      "\n",
      "  warnings.warn(_BOKEH_CLIENT_APP_WARNING_FULL)\n"
     ]
    }
   ],
   "source": [
    "from bokeh.client import push_session\n",
    "from bokeh.models import FixedTicker\n",
    "from bokeh.plotting import figure, curdoc, reset_output\n",
    "\n",
    "# reset output\n",
    "reset_output()\n",
    "\n",
    "# initialize alpha, beta\n",
    "tweets = fetch_tweets()\n",
    "alpha, beta = compute_alpha_and_beta(tweets=tweets)\n",
    "pdf_y_values = compute_pdf_y_values(alpha, beta)\n",
    "\n",
    "# create bokeh figure\n",
    "bokeh_figure = figure(\n",
    "    title='PDF of True Probability of a Tweet Containing Keyword',\n",
    "    x_axis_label='true_probability',\n",
    "    y_axis_label='probability_density',\n",
    "    width=1000,\n",
    "    height=600\n",
    ")\n",
    "bokeh_figure.xaxis[0].ticker=FixedTicker(ticks=list(np.linspace(0, 1, 21)))\n",
    "bokeh_line = bokeh_figure.line(X_VALUES, pdf_y_values, color=\"navy\", line_width=4)\n",
    "\n",
    "# open a session to keep our local document in sync with server\n",
    "session = push_session(curdoc())\n",
    "\n",
    "def update():\n",
    "    tweets = fetch_tweets()\n",
    "    alpha, beta = compute_alpha_and_beta(tweets=tweets)\n",
    "    pdf_y_values = compute_pdf_y_values(alpha, beta)\n",
    "    bokeh_line.data_source.data.update(y=pdf_y_values)\n",
    "\n",
    "curdoc().add_periodic_callback(update, 100)\n",
    "\n",
    "session.show(bokeh_figure)\n",
    "\n",
    "session.loop_until_closed()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
